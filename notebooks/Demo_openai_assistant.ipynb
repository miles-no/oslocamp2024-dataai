{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant Demo\n",
    "\n",
    "Forsøk på en rask test og demo av hvordan Assistants fungerer i OpenAI. Ideen er at man kan bruke dette til å lage en vector store som er søkbar. Kanksje ikke så nyttig for å spisse en CV men kan være interessant å se på. Spesielt siden disse vil være tilgjengelig i GUI når de er lagd, og visa versa. Men siden ChatGPT Teams lisensen er annerledes en openAI plattform der API vi bruker ligger så vil ikke disse være koblet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Her importerer vi bilbioteker, API nøkkler, og definerer en rolle beksrivelse som blir brukt senere (sånn at koden etterpå blir mer leselig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rolle_beskrivelse = \"\"\"1   Navn på oppdrag /\n",
    "prosjekt\n",
    "LLM Engineer (mulig teamleder) til nytt KI Team\n",
    "2   Kort beskrivelse av oppdraget\n",
    "Sikt etablerer et nytt team som jobber med kunstig intelligens på tvers av virksomheten. Dette\n",
    "vil støtte produkt-teamene i Sikt med kompetanse og gjennomføringskraft og realisere piloter\n",
    "på ny og bedre funksjonalitet.\n",
    "Vi ønsker med dette teamet og etablerere et sterkt fagmiljø for data science og KI i Sikt som\n",
    "gjør oss i stand til å identifisere, planlegge og utnytte flere av mulighetene som KI åpner for i\n",
    "produktene våre.\n",
    "Selv om hovedoppgaven til teamet blir å realisere faktiske produkter og ny funksjonalitet, blir\n",
    "det også en svært viktig å jobbe sammen med produkt-teamene for å identifisere de riktige\n",
    "initiativene, samt å dokumentere og formidle både internt og eksternt om både læring, feil og\n",
    "suksesser.\n",
    "Vi har identifisert to ulike roller som blir viktig for oss fra starten, og hvor vi søker en erfaren\n",
    "konsulent. En av disse rollene vil også ha funksjon som teamleder. Til stillingen som «LLM\n",
    "engineer» («Large Language Model engineer») søker vi en erfaren konsulent med følgende\n",
    "kvalifikasjoner:\n",
    "Kvalifikasjoner\n",
    "(dersom aktuell som teamleder) Erfaring med å lede og inspirere høytytende team\n",
    "for å fremme et positivt arbeidsmiljø og høy leveransekraft.\n",
    "\\n\n",
    "Evnen til å veilede og utvikle team-medlemmer, både faglig og personlig, for å styrke\n",
    "teamets kompetanse og karriereutvikling.\n",
    "\\n\n",
    "Kommunikasjon: Sterke muntlige og skriftlige kommunikasjonsevner for å forklare\n",
    "komplekse analyser og konklusjoner til et ikke-teknisk publikum.\n",
    "\\n\n",
    "Dyptgående programmeringskunnskap, fortrinnsvis Python.\n",
    "\\n\n",
    "Praktisk erfaring og utforsking av innovativ bruk av LLM via API det siste året.\n",
    "\\n\n",
    "Kunnskap og erfaring med open source språkmodeller, og fine-tuning av disse.\n",
    "\\n\n",
    "Erfaring med RAG (Retrieval Augmented Generation) med LangChain eller\n",
    "tilsvarende.\n",
    "\\n\n",
    "Grunnleggende forståelse for maskinlæring og NLP (Natural Language Processing)\n",
    "\\n\n",
    "Erfaring med å utvikle og vedlikeholde API-er.\n",
    "\\n\n",
    "God forståelse og erfaring med git, CI/CD, skyteknologi og Docker eller kubernetes.\n",
    "\\n\n",
    "Teamarbeid: Evnen til å jobbe effektivt i tverrfaglige team og samarbeide med andre\n",
    "fagområder.\n",
    "\\n\n",
    "Nysgjerrighet og lærevillighet: En evne til å holde seg oppdatert med de siste\n",
    "trendene og teknologiene innen AI og maskinlæring.\n",
    "\\n\n",
    "God skriftlig og muntlig fremstillingsevne på både norsk og engelsk\n",
    "Arbeidsoppgaver:\n",
    "\\n\n",
    "Sammen med produktteamene idémyldre, identifisere og planlegge nye piloter og\n",
    "initiativer.\n",
    "\\n\n",
    "Sammen med teamet utvikle ny funksjonalitet og tjenester med LLM og generativ AI.\n",
    "\\n\n",
    "Formidling og historiefortelling om arbeidet, prosessen og resultatene underveis\n",
    "\\n\n",
    "Bidra til godt samarbeid i produktteamet\n",
    "Personlige egenskaper:\n",
    "\\n\n",
    "Gode analytiske ferdigheter\n",
    "\\n\n",
    "Høy gjennomføringsevne\n",
    "\\n\n",
    "Presis i kommunikasjon\n",
    "\\n\n",
    "Svært gode samarbeidsevner\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definer en Assistant\n",
    "\n",
    "Første steg er å lage en assistent. Vi må gi den et navn, en instruks, en model, og definere om det er noen verktøy den skal bruke. Her bruker vi file_search som verktøy, for å kunne søke i opplasstede filer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_assistant = client.beta.assistants.create(\n",
    "  name=\"CV Spisser Assistent\",\n",
    "  instructions=\"\"\"\n",
    "    Du er en selger av konsulenter. Bruk informasjonen hentet fra kunnskapsbasen av CV'er til å forslå en spisset CV intro tekst for en gitt prosjektbeskrivelse./n\n",
    "    Du skal kun bruke info fra en gitt persons CV. Personen blir identifisert i prompten, sammen med prosjektbeskrivelsen. Den spisset CV intro teksten skal maks være 150 ord.\n",
    "  \"\"\",\n",
    "  model=\"gpt-4-turbo\",\n",
    "  tools=[{\"type\": \"file_search\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi må også lage en vector store som assistenten skal bruke for å hente ut informasjon fra opplastede filer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_store_CV = client.beta.vector_stores.create(\n",
    "    name = \"CV_store\",\n",
    "    expires_after={\"anchor\": \"last_active_at\", \"days\":3}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her laster vi in alle filer som ligger i data mappen (når denne demoen ble lagd var det kun en fil der) og laster de opp til vector store. I denne prosessen blir filene delt opp i mindre biter for å bli konvertert til en vector. Dette er en begrensning pga embedding modelen som blir brukt for konverteringen. Denne modellen tar input av en vis størrelse. Dermed vil søk i den slik database hente de segmentene av filen opplastet som best passer med det man spør etter. Dermed blir ikke nødvendigvis hele CV'en brukt når den svarer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_streams = [open(\"../data/\"+path, \"rb\") for path in os.listdir(\"../data/\")]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store_CV.id,\n",
    "    files = file_streams\n",
    ")\n",
    "\n",
    "# Oppdater assistent med en kobling til vector store\n",
    "cv_assistant = client.beta.assistants.update(\n",
    "    assistant_id=cv_assistant.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_CV.id]}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kommunisere til en assistent gjennom threads. Hver thread er ekvivalent med en chat i ChatGPT, og kan ha flere messages. En thread vil også da håndtere chat historikk.\n",
    "\n",
    "Det finnes per i dag ikke en metode for å liste opp alle aktive threads, så hvis man skal gå tilbake til en thread så må dens id lagres selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thread_1 = client.beta.threads.create(messages=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her lager vi en message som er koblet til en bestemt thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_x7TA7vcTUUVA148NsmKOMerM', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Bruk CV'en til Ask. Prosjektbeskrivelse: 1   Navn på oppdrag /\\nprosjekt\\nLLM Engineer (mulig teamleder) til nytt KI Team\\n2   Kort beskrivelse av oppdraget\\nSikt etablerer et nytt team som jobber med kunstig intelligens på tvers av virksomheten. Dette\\nvil støtte produkt-teamene i Sikt med kompetanse og gjennomføringskraft og realisere piloter\\npå ny og bedre funksjonalitet.\\nVi ønsker med dette teamet og etablerere et sterkt fagmiljø for data science og KI i Sikt som\\ngjør oss i stand til å identifisere, planlegge og utnytte flere av mulighetene som KI åpner for i\\nproduktene våre.\\nSelv om hovedoppgaven til teamet blir å realisere faktiske produkter og ny funksjonalitet, blir\\ndet også en svært viktig å jobbe sammen med produkt-teamene for å identifisere de riktige\\ninitiativene, samt å dokumentere og formidle både internt og eksternt om både læring, feil og\\nsuksesser.\\nVi har identifisert to ulike roller som blir viktig for oss fra starten, og hvor vi søker en erfaren\\nkonsulent. En av disse rollene vil også ha funksjon som teamleder. Til stillingen som «LLM\\nengineer» («Large Language Model engineer») søker vi en erfaren konsulent med følgende\\nkvalifikasjoner:\\nKvalifikasjoner\\n(dersom aktuell som teamleder) Erfaring med å lede og inspirere høytytende team\\nfor å fremme et positivt arbeidsmiljø og høy leveransekraft.\\n\\n\\nEvnen til å veilede og utvikle team-medlemmer, både faglig og personlig, for å styrke\\nteamets kompetanse og karriereutvikling.\\n\\n\\nKommunikasjon: Sterke muntlige og skriftlige kommunikasjonsevner for å forklare\\nkomplekse analyser og konklusjoner til et ikke-teknisk publikum.\\n\\n\\nDyptgående programmeringskunnskap, fortrinnsvis Python.\\n\\n\\nPraktisk erfaring og utforsking av innovativ bruk av LLM via API det siste året.\\n\\n\\nKunnskap og erfaring med open source språkmodeller, og fine-tuning av disse.\\n\\n\\nErfaring med RAG (Retrieval Augmented Generation) med LangChain eller\\ntilsvarende.\\n\\n\\nGrunnleggende forståelse for maskinlæring og NLP (Natural Language Processing)\\n\\n\\nErfaring med å utvikle og vedlikeholde API-er.\\n\\n\\nGod forståelse og erfaring med git, CI/CD, skyteknologi og Docker eller kubernetes.\\n\\n\\nTeamarbeid: Evnen til å jobbe effektivt i tverrfaglige team og samarbeide med andre\\nfagområder.\\n\\n\\nNysgjerrighet og lærevillighet: En evne til å holde seg oppdatert med de siste\\ntrendene og teknologiene innen AI og maskinlæring.\\n\\n\\nGod skriftlig og muntlig fremstillingsevne på både norsk og engelsk\\nArbeidsoppgaver:\\n\\n\\nSammen med produktteamene idémyldre, identifisere og planlegge nye piloter og\\ninitiativer.\\n\\n\\nSammen med teamet utvikle ny funksjonalitet og tjenester med LLM og generativ AI.\\n\\n\\nFormidling og historiefortelling om arbeidet, prosessen og resultatene underveis\\n\\n\\nBidra til godt samarbeid i produktteamet\\nPersonlige egenskaper:\\n\\n\\nGode analytiske ferdigheter\\n\\n\\nHøy gjennomføringsevne\\n\\n\\nPresis i kommunikasjon\\n\\n\\nSvært gode samarbeidsevner\"), type='text')], created_at=1714045414, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_uaSg9L9MWexWXw9ndsHi7qJA')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "message_data = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Bruk CV'en til Ask. Prosjektbeskrivelse: {Rolle_beskrivelse}\"\n",
    "}\n",
    "\n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread_1.id,\n",
    "    **message_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For å kjøre en thread å få en respons på en melding sent inn, må vi gjøre en run (man kan også sette opp en stream). Så kan vi liste opp alle messages gjor i en thread og parse responsen. Her er det lagt til litt støttekode for å formatere responsen til å legge ved siteringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Juhl Markestad er en dyktig og erfaren data scientist og data engineer med bred kunnskap og erfaring innen utvikling og implementering av avanserte AI-løsninger og datavitenskapelige prosjekter. Med en mastergrad i teoretisk fysikk fra Universitetet i Oslo, har han utviklet robuste ferdigheter i matematisk modellering og statistisk analyse. Ask har arbeidet med prosjekter som spenner over datavitenskap, maskinlæring, og kunstig intelligens i bransjer som finans, offentlig, og media. Han er sertifisert innen flere teknologier inkludert Azure Data Scientist og har praktisk erfaring med Python, AI-modellering med ChatGPT og RAG, samt teknologier som AWS og Azure  . Hans evne til teknologisk innovation og prosjektledelse kvalifiserer ham ypperlig for rollen som LLM Engineer hvor han vil kunne lede og inspirere teamet i utviklingen av ny funksjonalitet og tjenester ved bruk av de nyeste innen kunstig intelligens og maskinlæring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread_1.id, assistant_id=cv_assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread_1.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "\n",
    "# Hvis det finnes citations i output så blir de listet.\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Her er en kodesnutt for å fjerne en bestemt assistent og en bestemt thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.assistants.delete(assistant_id=cv_assistant.id)\n",
    "client.beta.threads.delete(thread_id=thread_1.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBS: Dette sletter alle assistenter koblet til dette API'et, inkludert de andre som bruker API'et har laget.\n",
    "# Venligst ikke slett andre sitt arbeid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assistant in client.beta.assistants.list():\n",
    "    print(assistant.id)\n",
    "    if assistant.tool_resources.file_search.vector_store_ids:\n",
    "        client.beta.vector_stores.delete(vector_store_id=assistant.tool_resources.file_search.vector_store_ids)\n",
    "    client.beta.assistants.delete(assistant_id=assistant.id)\n",
    "client.beta.assistants.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slett alle active vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vector_store in client.beta.vector_stores.list():\n",
    "    client.beta.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "client.beta.vector_stores.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slett alle opplastede file assosiert med en assistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[], object='list', has_more=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in client.files.list(purpose=\"assistants\"):\n",
    "    client.files.delete(file.id)\n",
    "client.files.list(purpose=\"assistants\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
