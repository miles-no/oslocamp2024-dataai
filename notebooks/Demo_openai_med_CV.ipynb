{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for bruk av openAI med cv data fra CV partner\n",
    "\n",
    "Dette er ment for å være en rask demo for å vise hvordan openai apiet fungerer, hvordan man kan laste inn CV data, og gi alle et godt utgangspunkt for hvordan å jobbe med ChatGPT gjennom et API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her bruker vi noe som heter dotenv for å laste miljø variabler fra en .env fil som ligger i root dir. Dette er en enkel måte å organisere miljøvariabler på per prosjekt, og man slipper all styret man typisk har i de forskjellige operativ systemene (Windows spesielt).\n",
    "\n",
    "Denne biten med kode antar at det finnes en fil i root med navn `.env`. I den filen bør det være en linje `OPENAI_API_KEY = ...` der man fyller in API nøkkelen. Denne filen ligger i .gitignore så derre må lage den selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her har jeg en beskrivelse på en rolle som jeg (Ask) har søkt på som et eksempel for bruk i denne demoen. Her har jeg kopiert beskrivelsen og gjort litt manuell redigering for å fjerne tegn som ikke er standard. Dette er litt prep arbeid før vi tar i bruk ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rolle_beskrivelse = \"\"\"1   Navn på oppdrag /\n",
    "prosjekt\n",
    "LLM Engineer (mulig teamleder) til nytt KI Team\n",
    "2   Kort beskrivelse av oppdraget\n",
    "Sikt etablerer et nytt team som jobber med kunstig intelligens på tvers av virksomheten. Dette\n",
    "vil støtte produkt-teamene i Sikt med kompetanse og gjennomføringskraft og realisere piloter\n",
    "på ny og bedre funksjonalitet.\n",
    "Vi ønsker med dette teamet og etablerere et sterkt fagmiljø for data science og KI i Sikt som\n",
    "gjør oss i stand til å identifisere, planlegge og utnytte flere av mulighetene som KI åpner for i\n",
    "produktene våre.\n",
    "Selv om hovedoppgaven til teamet blir å realisere faktiske produkter og ny funksjonalitet, blir\n",
    "det også en svært viktig å jobbe sammen med produkt-teamene for å identifisere de riktige\n",
    "initiativene, samt å dokumentere og formidle både internt og eksternt om både læring, feil og\n",
    "suksesser.\n",
    "Vi har identifisert to ulike roller som blir viktig for oss fra starten, og hvor vi søker en erfaren\n",
    "konsulent. En av disse rollene vil også ha funksjon som teamleder. Til stillingen som «LLM\n",
    "engineer» («Large Language Model engineer») søker vi en erfaren konsulent med følgende\n",
    "kvalifikasjoner:\n",
    "Kvalifikasjoner\n",
    "(dersom aktuell som teamleder) Erfaring med å lede og inspirere høytytende team\n",
    "for å fremme et positivt arbeidsmiljø og høy leveransekraft.\n",
    "\\n\n",
    "Evnen til å veilede og utvikle team-medlemmer, både faglig og personlig, for å styrke\n",
    "teamets kompetanse og karriereutvikling.\n",
    "\\n\n",
    "Kommunikasjon: Sterke muntlige og skriftlige kommunikasjonsevner for å forklare\n",
    "komplekse analyser og konklusjoner til et ikke-teknisk publikum.\n",
    "\\n\n",
    "Dyptgående programmeringskunnskap, fortrinnsvis Python.\n",
    "\\n\n",
    "Praktisk erfaring og utforsking av innovativ bruk av LLM via API det siste året.\n",
    "\\n\n",
    "Kunnskap og erfaring med open source språkmodeller, og fine-tuning av disse.\n",
    "\\n\n",
    "Erfaring med RAG (Retrieval Augmented Generation) med LangChain eller\n",
    "tilsvarende.\n",
    "\\n\n",
    "Grunnleggende forståelse for maskinlæring og NLP (Natural Language Processing)\n",
    "\\n\n",
    "Erfaring med å utvikle og vedlikeholde API-er.\n",
    "\\n\n",
    "God forståelse og erfaring med git, CI/CD, skyteknologi og Docker eller kubernetes.\n",
    "\\n\n",
    "Teamarbeid: Evnen til å jobbe effektivt i tverrfaglige team og samarbeide med andre\n",
    "fagområder.\n",
    "\\n\n",
    "Nysgjerrighet og lærevillighet: En evne til å holde seg oppdatert med de siste\n",
    "trendene og teknologiene innen AI og maskinlæring.\n",
    "\\n\n",
    "God skriftlig og muntlig fremstillingsevne på både norsk og engelsk\n",
    "Arbeidsoppgaver:\n",
    "\\n\n",
    "Sammen med produktteamene idémyldre, identifisere og planlegge nye piloter og\n",
    "initiativer.\n",
    "\\n\n",
    "Sammen med teamet utvikle ny funksjonalitet og tjenester med LLM og generativ AI.\n",
    "\\n\n",
    "Formidling og historiefortelling om arbeidet, prosessen og resultatene underveis\n",
    "\\n\n",
    "Bidra til godt samarbeid i produktteamet\n",
    "Personlige egenskaper:\n",
    "\\n\n",
    "Gode analytiske ferdigheter\n",
    "\\n\n",
    "Høy gjennomføringsevne\n",
    "\\n\n",
    "Presis i kommunikasjon\n",
    "\\n\n",
    "Svært gode samarbeidsevner\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For å komunnisere med OpenAI API'et så initialiserer vi et client objekt. Dette objektet håndterer hvor kommunikasjon med API'et på et litt høyere nivå.\n",
    "\n",
    "Det neste vi gjør her er å laste opp min CV i PDF format slik at denne filen er tilgjengelig for clienten å bruke.\n",
    "\n",
    "Så ber vi clienten å gjøre en chat completion. Dette er metoden får å interagere direkte med en chat. Denne historikken vil ikke bli husket til neste chat completion så hvis man vil ha med historikk så må det være en del av inputet til en slik chat completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "CV = client.files.create(\n",
    "  file=open(\"../data/AskJuhlMarkestad_pdf_cv.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her gir vi modelen en system melding `\"role\": \"system\", \"content\": ...`, det vil si noe den skal ta med i prompten for hver interaksjon med chaten. I dette tilfellet gir vi den en beskrivelse av hva dens generelle oppgave er. Dette kan også inneholde mer info om hvordan svar skal generelt formateres, eller om f.eks. tone den skal svare med.\n",
    "\n",
    "Selve meldingen som skal gis kommer under rollen `\"role\": \"user\", \"content\": ...`. Her gir vi mer spesifikke instrukser med noe formatering for å identifisere hva som er CV og hva som er rolle beskrivelse. Her har vi lagt in den spesifikke referansen til den opplatede CV'en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Erfaren LLM Engineer med ekspertise innen Large Language Models og teamledelse. Jeg har ledet høytytende team for å skape et positivt arbeidsmiljø og sikre høy leveransekraft. Min evne til å veilede og utvikle medlemmer styrker teamets kompetanse og karrierevekst. Med sterke kommunikasjonsevner formidler jeg komplekse analyser og konklusjoner til et ikke-teknisk publikum. Min dype programmeringskunnskap inkluderer Python, samt praktisk erfaring med innovativ bruk av LLM via API og fine-tuning av open source språkmodeller. Jeg har erfaring med RAG og grunnleggende forståelse for maskinlæring og NLP. Ved å utvikle og vedlikeholde API-er og jobbe effektivt i tverrfaglige team, bidrar jeg til å identifisere, planlegge og realisere nye piloter og initiativer. Gjennom god samarbeidsevne og analytiske ferdigheter leverer jeg presist og effektivt i teammiljøer.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Du hjelper konsulenter med å spisse deres CV intro text for en gitt rolle beskrivelse.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Skriv en CV intro tekst på 150 ord for en gitt CV og en gitt rolle beskrivelse: \\n CV: {CV.id} \\n Rolle Beskrivelse: {Rolle_beskrivelse}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hver fil vi har lastet opp koster 0.2$ per dag. \n",
    "\n",
    "Ved å kjøre koden under så kan man se hvilke files som er lastet opp for et gitt formål, eller totalt sett. Dokumentene vil bli delt med alle som har API tilgang til instansen som laget API nøkkelen. Hver OBS på at man kan laste opp samme fil flere ganger og dermed øke kostnadene. \n",
    "\n",
    "Derfor har jeg og lagt ved en liten kodesnutt som sletter alle filene opplastet som eksempel på hvordan man kan rengjøre miljøet sitt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-7EAmaQ2d6jDl9aFhWQqsnh2I', bytes=173730, created_at=1712659662, filename='AskJuhlMarkestad_pdf_cv.pdf', object='file', purpose='assistants', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.list(purpose=\"assistants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[], object='list', has_more=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in client.files.list(purpose=\"assistants\"):\n",
    "    client.files.delete(file.id)\n",
    "client.files.list(purpose=\"assistants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
